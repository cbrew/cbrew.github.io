---
layout: post
title: "Is Chat GPT a confidence trick?"
date: 2000-03-30 12:41:00 EST
categories: nlp chatgpt
---
## Confidence tricks

Confidence tricksters work by getting us to trust them, then getting us to do things that benefit them, but which we would not otherwise do. Usually, the 
trick depends on creating an illusion. If you get an unexpected call that claims to be from your bank, there is a chance that you
actually speaking to someone else, and they are not really trying to help you. They may want to get your login details and use them to empty your account. 
That's why banks promise that they will never ask for your account numbers over the phone or in an email. Tricks like this go back to ancient times: all that 
the internet has done is made some of them easier to do and harder to detect. To be fair, the internet has probably made other scams harder: it is no longer 
as easy as it once was to turn up in some remote place and claim to be a medical doctor. Then again, on the internet nobody knows if you are a dog. Most people, most of 
the time, have meaningful interactions with people whom they have never met and never expect to meet. The possibilities for deception are endless, and some 
of them enable confidence tricks.

## Chat GPT

Chat GPT is a so-called _generative ai_ system that has created a lot of excitement. It can produce written text that is a very good match, in terms of style, 
for what would be produced by an expert. You name the field, if there is written text about it, Chat GPT can produce text whose style closely resembles what an expert
might produce. Either Chat GPT is actually a superhumanly smart polymath or it is a counter-example to the common assumption that if you write like an expert you must be an
expert. I tend to believe the second alternative. That's partly because its performance on things that I know about is not reliably good. If I am right, 
we are certainly dealing with an illusion. Its creators, OpenAI, are straightforward in admitting that 
they do intend to replace the current research prototype with a paid-for service, and their revenue projections, if realized, will certainly make the 
company rich. Perhaps this is all above board. Or perhaps Open AI is fooling itself, or perhaps Open AI knows exactly what is doing and trying to fool us. 
If the third alternative is right, the whole thing is a confidence trick and we are the marks. Let's look at this more closely. 
