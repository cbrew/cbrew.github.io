---
layout: post
title: "Galactica"
date: 2022-11-22
categories: generative text LLM
---

This week, Meta announced a language model called Galactica that was able, given a query, to produce plausible looking texts in scientific domains.
A specific claim in [the paper](https://galactica.org/static/paper.pdf) is:

> ... It could synthesize knowledge by generating secondary content automatically: such as literature reviews, 
encyclopedia articles, lecture notes and more. And lastly, it could organize different modalities: linking papers with code, protein sequences with compounds, theories with
LaTeX, and more. ...

The team were kind enough to provide a live demo, beautifully presented, which demonstrated some of these capabilities. Like everyone else, I tried it, and can report
that it was reliably pretty good at capturing the style. Certainly, the vision of being able to produce customized secondary content on demand is 
attractive. On the other hand, what if the secondary content is unreliable or misleading? It is well-known that texts generated by previous language models
were impressively fluent, especially within a narrow window, but prone to inconsistencies at higher levels of structure. For example, in a story, the topic may
drift in unexpected ways, or character names may change for no apparent reason, or things may change color more or less at random. 
It appears that these models are not maintaining a consistent enough representation of "what is going on in the story". An advocate will argue that they must
be doing at least some of this, because aspects of the output *are* consistent, while a skeptic will draw attention to the deficiencies.
If the sole purpose of the model is to generate engaging output, this might be OK. If, for some reason, you need the story to be consistent, it is not.

Where does Galactica, which targets scientific knowledge, stand relative to this kind of requirement? Unfortunately, despite all its strengths, not 
outstandingly well. In fact, when people began to play with the demo, it turned out not to be at all hard to obtain output that was variously offensive, 
disturbing, generally misguided or just plain wrong. This produced a storm of bad publicity, after which the demo was taken down. Part of the issue is 
the simple fact that if a high-profile company puts a demo up on the Internet, there will always be people who will be motivated to break the demo. 
But there is clearly more to it than that.

One issue is the enabling of scientific malpractice. Koestler's "Case of the Midwife Toad" and other examples, such as Cyril Burt's twin studies, show 
that researchers can gain short-term benefit and reputation by publishing bogus studies. The base rate of serious scientific malpractice in the peer-reviewed and published research literature is unknown, probably quite low, and the review process is designed to keep it that way. It is convenient that substantively bad scientific work is often bad along other easily detectable dimensions, such as terminology and style. This facilitates the peer review process, because rejecting a paper that is obviously very badly written takes less reviewer effort. Since Galactica produces text that looks good along these dimensions, and people will submit such papers, it runs the risk of burdening the review process.


